{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.132  Python-3.8.17 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 960M, 4096MiB)\n",
      "Setup complete  (8 CPUs, 15.8 GB RAM, 174.6/238.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__,torch.cuda.is_available())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from mmocr.apis import MMOCRInferencer\n",
    "\n",
    "from craft_text_detector import Craft\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "ultralytics.checks()\n",
    "\n",
    "import imutils\n",
    "\n",
    "import glob\n",
    "import  traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C://Program Files//Tesseract-OCR//tesseract.exe'\n",
    "\n",
    "os.environ[\"TESSDATA_PREFIX\"] =  \"C://Program Files//Tesseract-OCR//tessdata\"\n",
    "custom_config = r'-c preserve_interword_spaces=5 --oem 3 --psm 8 '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Craft Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "craft_detector = Craft( crop_type=\"poly\", cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Craft Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CraftModule:\n",
    "    def __init__(self,craft_detector,craft_extractor):\n",
    "        self.craft_extractor = craft_extractor\n",
    "        self.craft_detector = craft_detector\n",
    "        self.boxes = None\n",
    "        self.image = None\n",
    "        self.file = None\n",
    "    \n",
    "    def plot_image(self,img):\n",
    "        plt.axis('off');\n",
    "        plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB));\n",
    "        plt.show();\n",
    "\n",
    "    def rotate_image(self):\n",
    "        img = self.image.copy()\n",
    "        image = img.copy()\n",
    "        boxes = self.craft_detector.detect_text(img)['boxes']\n",
    "        angled_boxes = []\n",
    "\n",
    "        # Get angled boxes\n",
    "        for box in boxes:\n",
    "            if len(box) >= 3:  # Ensure at least 3 points for a polygon\n",
    "                # Convert box points to numpy array for easier manipulation\n",
    "                box_points = np.array(box, dtype=np.int32).reshape(-1, 2)\n",
    "\n",
    "                # Calculate the minimum bounding rectangle\n",
    "                rotated_rect = cv2.minAreaRect(box_points)\n",
    "                box_vertices = cv2.boxPoints(rotated_rect)\n",
    "                box_vertices = np.int0(box_vertices)\n",
    "                angled_boxes.append(box_vertices)\n",
    "                cv2.drawContours(img, [box_vertices], 0, (255, 0, 0), 2)\n",
    "        # plt.imshow(img)\n",
    "\n",
    "        try:\n",
    "            # Get largest contour and rotate on basis of that\n",
    "            largest_contour = max(angled_boxes, key=cv2.contourArea)\n",
    "            rows,cols = img.shape[:2]\n",
    "            [vx,vy,x,y] = cv2.fitLine(largest_contour, cv2.DIST_L2,0,0.01,0.01)\n",
    "            lefty = (-x*vy/vx) + y\n",
    "            righty = ((cols-x)*vy/vx)+y\n",
    "\n",
    "            angle_rad = np.arctan2(vy, vx)\n",
    "            angle = np.degrees(angle_rad)[0]\n",
    "\n",
    "            height, width = img.shape[:2]\n",
    "            center = (width // 2, height // 2)\n",
    "            \n",
    "            if angle != 90:\n",
    "                rotation_matrix = cv2.getRotationMatrix2D(center, angle , scale=1.0)\n",
    "                self.image = cv2.warpAffine(self.image, rotation_matrix , (width, height))   \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def detect_text(self,image,file_name):\n",
    "        self.file = file_name\n",
    "        self.image = image\n",
    "        cv2.imwrite(f'results/{self.file}_0.jpg',image)\n",
    "\n",
    "        # self.plot_image(image)\n",
    "        self.rotate_image()\n",
    "        self.boxes = self.craft_extractor.detect_text(self.image)['boxes']\n",
    "        # self.plot_image(self.image)\n",
    "        # print('------------ Detected Text Regions ------------')\n",
    "        # self.draw_rectangles()\n",
    "        # print('------------ Croped Text Regions ------------')\n",
    "        self.show_cropped_image()\n",
    "\n",
    "    def get_bounding_boxes(self,box):\n",
    "        flat_box = box.flatten()\n",
    "        x_min = round(min([flat_box[x] for x in [0,2,4,6]]))\n",
    "        y_min = round(min([flat_box[y] for y in [1,3,5,7]]))\n",
    "        x_max = round(max([flat_box[x] for x in [0,2,4,6]]))\n",
    "        y_max = round(max([flat_box[y] for y in [1,3,5,7]]))\n",
    "\n",
    "        return x_min,y_min,x_max,y_max\n",
    "    \n",
    "    # def draw_rectangles(self):\n",
    "    #     image_rect = self.image.copy()\n",
    "    #     for box in self.boxes:\n",
    "    #         x_min,y_min,w,h = cv2.boundingRect(box)\n",
    "    #         image_rect = cv2.rectangle(image_rect, (x_min,y_min), (x_min + w,y_min + h), (255,0,0), 2)\n",
    "        # self.plot_image(image_rect)\n",
    "            \n",
    "    def show_cropped_image(self):\n",
    "        count = 1\n",
    "        for box in self.boxes:\n",
    "            x_min,y_min,x_max,y_max = self.get_bounding_boxes(box)\n",
    "            roi = self.image[y_min : y_max , x_min : x_max].copy()\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "            roi_invert = cv2.bitwise_not(roi_gray)\n",
    "            thresh = cv2.threshold(roi_gray, 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "            edges = cv2.Canny(roi, 27, 255)\n",
    "            # self.plot_image(roi_gray)\n",
    "            # self.plot_image(cv2.bitwise_not(roi_gray))\n",
    "\n",
    "\n",
    "            # contour, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            # print(len(contour))\n",
    "            \n",
    "            # text_english_t = pytesseract.image_to_string(thresh,lang = 'eng', config = custom_config)\n",
    "            # text_nepali_t = pytesseract.image_to_string(thresh,lang = 'nep', config = custom_config)\n",
    "            # text_nepali_hin_t = pytesseract.image_to_string(thresh,lang = 'nep+hin', config = custom_config)\n",
    "\n",
    "\n",
    "            text_english = pytesseract.image_to_string(roi_invert,lang = 'eng', config = custom_config)\n",
    "            text_nepali = pytesseract.image_to_string(roi_invert,lang = 'nep', config = custom_config)\n",
    "            text_nepali_hin = pytesseract.image_to_string(roi_invert,lang = 'nep+hin', config = custom_config)\n",
    "\n",
    "\n",
    "            # print(f'English (gray) : {text_english}')\n",
    "            # print(f'Nepali (gray) : {text_nepali}')\n",
    "            # print(f'Nepali + Hindi (gray) : {text_nepali_hin}')\n",
    "\n",
    "            # print(f'English (thresh) : {text_english_t}')\n",
    "            # print(f'Nepali (thresh) : {text_nepali_t}')\n",
    "            # print(f'Nepali + Hindi (thresh) : {text_nepali_hin_t}')\n",
    "\n",
    "            cv2.imwrite(f'results/{self.file}_{count}.jpg',roi)\n",
    "            \n",
    "            with open(f'results/{self.file}_{count}.txt', \"w\") as file:\n",
    "                file.write(f'English : {text_english}\\n')\n",
    "                file.write(f'Nepali : {text_nepali}\\n')\n",
    "                file.write(f'Nepali + Hindi : {text_nepali_hin}\\n')\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "            # self.plot_image(roi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "craft_extractor = Craft( crop_type=\"box\", cuda=True,text_threshold=0.8,link_threshold=0.8,low_text=0.18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type=['JPG','JPEG','PNG','JFIF']\n",
    "images=[]\n",
    "#for copying later\n",
    "filename=[]\n",
    "for format in file_type:\n",
    "    for path in glob.glob(f\"testing2/*.{format}\"):\n",
    "        filename.append(path)\n",
    "        images.append(cv2.imread(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing2/2021_10_13_042806.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2021_10_13_042806.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = str(filename[0].replace('\\\\','/'))\n",
    "print(file)\n",
    "file.split(\"/\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 8 billboards, 338.1ms\n",
      "Speed: 6.0ms preprocess, 338.1ms inference, 12.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\craft_text_detector\\craft_utils.py:415: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  polys = np.array(polys)\n",
      "c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\craft_text_detector\\predict.py:110: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  polys_as_ratio = np.array(polys_as_ratio)\n",
      "\n",
      "0: 320x640 1 billboard, 294.2ms\n",
      "Speed: 6.0ms preprocess, 294.2ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 billboards, 511.8ms\n",
      "Speed: 5.0ms preprocess, 511.8ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 billboards, 497.7ms\n",
      "Speed: 6.0ms preprocess, 497.7ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 billboards, 505.6ms\n",
      "Speed: 5.0ms preprocess, 505.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 billboards, 462.7ms\n",
      "Speed: 6.0ms preprocess, 462.7ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 billboard, 536.6ms\n",
      "Speed: 5.0ms preprocess, 536.6ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 billboards, 304.2ms\n",
      "Speed: 3.0ms preprocess, 304.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 billboard, 293.2ms\n",
      "Speed: 5.0ms preprocess, 293.2ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 billboards, 477.7ms\n",
      "Speed: 6.0ms preprocess, 477.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 billboard, 456.8ms\n",
      "Speed: 6.0ms preprocess, 456.8ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 billboards, 299.2ms\n",
      "Speed: 4.0ms preprocess, 299.2ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 billboards, 408.9ms\n",
      "Speed: 6.0ms preprocess, 408.9ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 billboard, 483.7ms\n",
      "Speed: 5.0ms preprocess, 483.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 billboards, 405.9ms\n",
      "Speed: 6.0ms preprocess, 405.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 billboards, 297.2ms\n",
      "Speed: 4.0ms preprocess, 297.2ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 billboard, 1759.3ms\n",
      "Speed: 4.0ms preprocess, 1759.3ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 1764.3ms\n",
      "Speed: 28.9ms preprocess, 1764.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 4, in <module>\n",
      "    detected_boards[0].boxes.data = torch.stack([box for box in detected_boards[0].boxes.data])\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "\n",
      "0: 320x640 3 billboards, 1753.3ms\n",
      "Speed: 100.7ms preprocess, 1753.3ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 billboards, 1822.1ms\n",
      "Speed: 101.6ms preprocess, 1822.1ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 billboard, 1868.0ms\n",
      "Speed: 66.8ms preprocess, 1868.0ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 billboards, 1880.0ms\n",
      "Speed: 110.2ms preprocess, 1880.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 5 billboards, 1917.9ms\n",
      "Speed: 108.8ms preprocess, 1917.9ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 15, in <module>\n",
      "    CraftModule(craft_detector,craft_extractor).detect_text(roi,roi_file_name)\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\508980397.py\", line 60, in detect_text\n",
      "    self.rotate_image()\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\508980397.py\", line 17, in rotate_image\n",
      "    boxes = self.craft_detector.detect_text(img)['boxes']\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\craft_text_detector\\__init__.py\", line 131, in detect_text\n",
      "    prediction_result = get_prediction(\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\craft_text_detector\\predict.py\", line 68, in get_prediction\n",
      "    y, feature = craft_net(x)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\", line 169, in forward\n",
      "    return self.module(*inputs[0], **kwargs[0])\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\craft_text_detector\\models\\craftnet.py\", line 65, in forward\n",
      "    sources = self.basenet(x)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\craft_text_detector\\models\\basenet\\vgg16_bn.py\", line 63, in forward\n",
      "    h = self.slice1(X)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_9628\\3105967426.py\", line 3, in <module>\n",
      "    detected_boards = model(image)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 111, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 255, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 190, in __call__\n",
      "    return list(self.stream_inference(source, model))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 243, in stream_inference\n",
      "    with profilers[0]:\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 39, in __enter__\n",
      "    self.start = self.time()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py\", line 54, in time\n",
      "    torch.cuda.synchronize()\n",
      "  File \"c:\\Users\\Ghost\\anaconda3\\envs\\galli_maps\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 688, in synchronize\n",
      "    return torch._C._cuda_synchronize()\n",
      "RuntimeError: CUDA error: the launch timed out and was terminated\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,image in enumerate(images):\n",
    "    try:\n",
    "        detected_boards = model(image)\n",
    "        detected_boards[0].boxes.data = torch.stack([box for box in detected_boards[0].boxes.data])\n",
    "        boxes = detected_boards[0].boxes.data\n",
    "        file_name = filename[index].replace('\\\\','/')\n",
    "        cv2.imwrite(f'results/{file_name.split(\"/\")[1]}',image)\n",
    "        count = 0\n",
    "        for box in boxes:\n",
    "            x1,y1,x2,y2 = int(box[0]),int(box[1]),int(box[2]),int(box[3])\n",
    "\n",
    "            roi =  image[y1 : y2, x1 : x2]\n",
    "            count += 1\n",
    "            roi_file_name = f'{file_name.split(\"/\")[1].split(\".\")[0]}_{count}'\n",
    "            CraftModule(craft_detector,craft_extractor).detect_text(roi,roi_file_name)\n",
    "    except Exception:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galli_maps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
